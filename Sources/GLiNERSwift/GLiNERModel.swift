import Foundation
@preconcurrency import CoreML

/// High-level API for GLiNER zero-shot named entity recognition
public class GLiNERModel {
    private static let aneRequiredSequenceLength = 512

    fileprivate let encoder: GLiNEREncoder
    fileprivate let tokenizer: GLiNERTokenizer
    private let spanScorer: SpanScorer
    private let spanDecoder: SpanDecoder
    private let config: Configuration
    private let padInputsToMaxLength: Bool
    private let chunkProcessor: ChunkProcessor
    private let textChunker: TextChunker
    fileprivate let gliner2SpanPipeline: GLiNER2SpanPipeline?
    fileprivate let gliner2MaxSpanWidth: Int?
    
    /// Initialize with bundled model (base GLiNER2)
    public convenience init(
        config: Configuration = .default,
        encoderComputeUnits: MLComputeUnits = .cpuAndGPU
    ) async throws {
        let padInputs = encoderComputeUnits == .all
        let encoder = try GLiNEREncoder(computeUnits: encoderComputeUnits)
        let tokenizer = try GLiNERTokenizer(
            maxLength: GLiNERModel.tokenizerLength(
                requested: config.maxSequenceLength,
                padInputsToMaxLength: padInputs
            )
        )
        try self.init(
            config: config,
            padInputsToMaxLength: padInputs,
            encoder: encoder,
            tokenizer: tokenizer
        )
    }
    
    /// Initialize with custom model and tokenizer
    /// - Parameters:
    ///   - modelURL: URL to .mlpackage
    ///   - tokenizerURL: URL to tokenizer directory
    ///   - config: Configuration
    public convenience init(
        modelURL: URL,
        tokenizerURL: URL,
        config: Configuration = .default,
        encoderComputeUnits: MLComputeUnits = .cpuAndGPU
    ) async throws {
        let padInputs = encoderComputeUnits == .all
        let encoder = try GLiNEREncoder(modelURL: modelURL, computeUnits: encoderComputeUnits)
        let tokenizer = try GLiNERTokenizer(
            maxLength: GLiNERModel.tokenizerLength(
                requested: config.maxSequenceLength,
                padInputsToMaxLength: padInputs
            ),
            tokenizerDirectory: tokenizerURL
        )
        try self.init(
            config: config,
            padInputsToMaxLength: padInputs,
            encoder: encoder,
            tokenizer: tokenizer
        )
    }

    /// Initialize using a manifest generated by `Scripts/convert_to_coreml.py`.
    /// - Parameters:
    ///   - manifestURL: Location of `export_manifest.json`.
    ///   - config: Runtime configuration overrides.
    ///   - encoderComputeUnits: Desired compute units for the encoder.
    public convenience init(
        manifestURL: URL,
        config: Configuration = .default,
        encoderComputeUnits: MLComputeUnits = .cpuAndGPU
    ) async throws {
        let resources = try GLiNER2Resources(manifestURL: manifestURL)
        try await self.init(gliner2Resources: resources, config: config, encoderComputeUnits: encoderComputeUnits)
    }

    /// Initialize using a pre-loaded set of GLiNER2 resources.
    /// - Parameters:
    ///   - gliner2Resources: Pre-resolved manifest and artifact URLs.
    ///   - config: Runtime configuration overrides.
    ///   - encoderComputeUnits: Desired compute units for the encoder.
    convenience init(
        gliner2Resources resources: GLiNER2Resources,
        config: Configuration = .default,
        encoderComputeUnits: MLComputeUnits = .cpuAndGPU
    ) async throws {
        let padInputs = encoderComputeUnits == .all
        let encoder = try GLiNEREncoder(modelURL: resources.encoderURL, computeUnits: encoderComputeUnits)
        let tokenizer = try GLiNERTokenizer(
            maxLength: GLiNERModel.tokenizerLength(
                requested: config.maxSequenceLength,
                padInputsToMaxLength: padInputs
            ),
            tokenizerDirectory: resources.tokenizerURL,
            gliner2Config: GLiNER2PromptConfiguration()
        )
        let spanPipeline = try GLiNER2SpanPipeline(resources: resources, computeUnits: encoderComputeUnits)
        try self.init(
            config: config,
            padInputsToMaxLength: padInputs,
            encoder: encoder,
            tokenizer: tokenizer,
            gliner2SpanPipeline: spanPipeline,
            gliner2MaxSpanWidth: resources.manifest.maxWidth
        )
    }
    
    /// Extract entities from text
    /// - Parameters:
    ///   - text: Input text
    ///   - labels: Array of label types to extract (e.g., ["person", "organization"])
    ///   - threshold: Optional confidence threshold (overrides config)
    ///   - config: Optional custom configuration (overrides instance config)
    /// - Returns: Array of extracted entities
    public func extractEntities(
        from text: String,
        labels: [String],
        threshold: Float? = nil,
        config: Configuration? = nil
    ) async throws -> [Entity] {
        guard !labels.isEmpty else { return [] }

        var workingConfig = config ?? self.config
        if let threshold {
            workingConfig.threshold = threshold
        }

        do {
            if textChunker.shouldChunk(text: text) {
                return try await extractEntitiesWithChunking(
                    from: text,
                    labels: labels,
                    config: workingConfig
                )
            }
            return try await runExtraction(
                text: text,
                labels: labels,
                config: workingConfig
            )
        } catch let error as GLiNERError {
            if case .tokenizerError = error {
                return try await extractEntitiesWithChunking(
                    from: text,
                    labels: labels,
                    config: workingConfig
                )
            }
            throw error
        }
    }
    
    private func toMilliseconds(_ duration: Duration) -> Double {
        let components = duration.components
        let seconds = Double(components.seconds)
        let attoseconds = Double(components.attoseconds)
        return seconds * 1_000.0 + attoseconds / 1_000_000_000_000_000.0
    }
    
    /// Extract entities from multiple texts (batch processing)
    /// - Parameters:
    ///   - texts: Array of input texts
    ///   - labels: Array of label types
    ///   - threshold: Optional threshold
    ///   - config: Optional configuration
    /// - Returns: Array of entity arrays (one per text)
    public func extractEntities(
        from texts: [String],
        labels: [String],
        threshold: Float? = nil,
        config: Configuration? = nil
    ) async throws -> [[Entity]] {
        // Process each text independently
        // TODO: Implement true batching for better performance
        var results: [[Entity]] = []
        
        for text in texts {
            let entities = try await extractEntities(
                from: text,
                labels: labels,
                threshold: threshold,
                config: config
            )
            results.append(entities)
        }
        
        return results
    }
    
    /// Clear label cache
    public func clearCache() {}
    
    // MARK: - Classification support
    
    /// Classify text using GLiNER2 classifier head.
    /// - Parameters:
    ///   - text: Input text
    ///   - labels: Classification labels
    ///   - multiLabel: Whether to allow multiple labels
    ///   - threshold: Confidence threshold for predictions
    /// - Returns: Classification predictions
    func classifyText(
        _ text: String,
        labels: [String],
        multiLabel: Bool = false,
        threshold: Float = 0.5
    ) async throws -> [(label: String, score: Float)] {
        guard let pipeline = gliner2SpanPipeline else {
            throw GLiNERError.invalidInput("Classification requires GLiNER2 pipeline")
        }
        
        // Build classification schema with [C] prefix
        let classificationLabels = labels.map { "[C] \($0)" }
        
        // Encode with classification schema
        let encoding = try tokenizer.encodeGLiNER2SchemaInput(
            text: text,
            labels: classificationLabels,
            maxSpanWidth: gliner2MaxSpanWidth
        )
        
        // Run encoder
        let hiddenStates = try await encoder.encode(
            inputIds: encoding.inputIds,
            attentionMask: encoding.attentionMask
        )
        
        // Run pipeline to get classifier logits
        let result = try await pipeline.run(hiddenStates: hiddenStates, encoding: encoding)
        
        // Extract classification predictions from classifier logits
        let predictions = extractClassificationPredictions(
            from: result.classifierLogits,
            labels: labels,
            multiLabel: multiLabel,
            threshold: threshold
        )
        
        return predictions
    }
    
    private func extractClassificationPredictions(
        from logits: MLMultiArray,
        labels: [String],
        multiLabel: Bool,
        threshold: Float
    ) -> [(label: String, score: Float)] {
        // Logits shape: [num_labels]
        // Extract logits and apply sigmoid/softmax
        guard logits.count >= labels.count else {
            return []
        }
        
        let scores: [Float]
        do {
            let rawLogits = try logits.withUnsafeFloat32Buffer { Array($0) }
            
            if multiLabel {
                // Apply sigmoid for multi-label
                scores = rawLogits.prefix(labels.count).map { sigmoid($0) }
            } else {
                // Apply softmax for single-label
                scores = softmax(Array(rawLogits.prefix(labels.count)))
            }
        } catch {
            return []
        }
        
        // Build predictions
        var predictions: [(label: String, score: Float)] = []
        for (index, label) in labels.enumerated() {
            let score = scores[index]
            if score >= threshold {
                predictions.append((label: label, score: score))
            }
        }
        
        // Sort by score descending
        predictions.sort { $0.score > $1.score }
        
        return predictions
    }
    
    private func sigmoid(_ x: Float) -> Float {
        return 1.0 / (1.0 + exp(-x))
    }
    
    private func softmax(_ logits: [Float]) -> [Float] {
        guard !logits.isEmpty else { return [] }
        
        // Subtract max for numerical stability
        let maxLogit = logits.max() ?? 0
        let exps = logits.map { exp($0 - maxLogit) }
        let sumExps = exps.reduce(0, +)
        
        return exps.map { $0 / sumExps }
    }

    private init(
        config: Configuration,
        padInputsToMaxLength: Bool,
        encoder: GLiNEREncoder,
        tokenizer: GLiNERTokenizer,
        gliner2SpanPipeline: GLiNER2SpanPipeline? = nil,
        gliner2MaxSpanWidth: Int? = nil
    ) throws {
        self.config = config
        self.padInputsToMaxLength = padInputsToMaxLength
        self.encoder = encoder
        self.tokenizer = tokenizer
        self.gliner2SpanPipeline = gliner2SpanPipeline
        self.gliner2MaxSpanWidth = gliner2MaxSpanWidth
        let metadata = try SpanHeadMetadataProvider.metadata()
        let scoringModel = try GLiNERSpanScoringModel()
        self.spanScorer = SpanScorer(metadata: metadata, scoringModel: scoringModel)
        self.spanDecoder = SpanDecoder()
        self.chunkProcessor = ChunkProcessor(config: config)
        self.textChunker = TextChunker(
            maxCharacters: GLiNERModel.chunkCharacterLimit(for: config),
            overlapCharacters: GLiNERModel.chunkOverlap(for: config),
            maxWords: max(spanScorer.maxWordCount - 8, 1)
        )
    }
}

private extension GLiNERModel {
    static func tokenizerLength(requested: Int, padInputsToMaxLength: Bool) -> Int {
        guard padInputsToMaxLength else { return requested }
        return max(requested, aneRequiredSequenceLength)
    }

    static func chunkCharacterLimit(for config: Configuration) -> Int {
        max(config.maxSequenceLength * 8, 2048)
    }

    static func chunkOverlap(for config: Configuration) -> Int {
        max(config.strideLength * 4, 256)
    }
}

private extension GLiNERModel {
    func runExtraction(text: String, labels: [String], config: Configuration) async throws -> [Entity] {
        if config.useGLiNER2Pipeline, let pipeline = gliner2SpanPipeline {
            return try await runGLiNER2Extraction(
                text: text,
                labels: labels,
                config: config,
                pipeline: pipeline
            )
        }
        return try await runLegacyExtraction(text: text, labels: labels, config: config)
    }

    func runLegacyExtraction(text: String, labels: [String], config: Configuration) async throws -> [Entity] {
        let clock = ContinuousClock()
        let t0 = clock.now
        let encoding = try tokenizer.encodePrompted(text: text, labels: labels, padToMaxLength: padInputsToMaxLength)
        guard encoding.textWordCount > 0 else { return [] }
        let t1 = clock.now

        let hiddenStates = try await encoder.encode(
            inputIds: encoding.inputIds,
            attentionMask: encoding.attentionMask
        )
        let t2 = clock.now

        let spanScores = try await spanScorer.score(
            hiddenStates: hiddenStates,
            encoding: encoding,
            labelCount: labels.count
        )
        let t3 = clock.now

        let entities = spanDecoder.decode(
            scores: spanScores,
            labels: labels,
            threshold: config.threshold,
            text: text,
            wordRanges: encoding.textWordRanges
        )
        let t4 = clock.now

        let tokenizeMs = toMilliseconds(t0.duration(to: t1))
        let encodeMs = toMilliseconds(t1.duration(to: t2))
        let scoreMs = toMilliseconds(t2.duration(to: t3))
        let decodeMs = toMilliseconds(t3.duration(to: t4))
        print("⏱️ Tokenize: \(String(format: "%.2f", tokenizeMs))ms | Encode: \(String(format: "%.2f", encodeMs))ms | Score: \(String(format: "%.2f", scoreMs))ms | Decode: \(String(format: "%.2f", decodeMs))ms")

        return entities
    }

    func runGLiNER2Extraction(
        text: String,
        labels: [String],
        config: Configuration,
        pipeline: GLiNER2SpanPipeline
    ) async throws -> [Entity] {
        let clock = ContinuousClock()
        let t0 = clock.now
        let encoding = try tokenizer.encodeGLiNER2SchemaInput(
            text: text,
            labels: labels,
            maxSpanWidth: gliner2MaxSpanWidth
        )
        guard !encoding.textTokens.isEmpty else { return [] }
        let t1 = clock.now

        let hiddenStates = try await encoder.encode(
            inputIds: encoding.inputIds,
            attentionMask: encoding.attentionMask
        )
        if let first = hiddenStates.first, encoding.textTokens.count < 40 {
            let norm = sqrt(first.reduce(0) { $0 + $1 * $1 })
            print("[DEBUG] Encoder first-token norm: \(norm)")
        }
        let t2 = clock.now

        let result = try await pipeline.run(hiddenStates: hiddenStates, encoding: encoding)
        guard result.predictedCount > 0 else { return [] }
        let builder = GLiNER2SpanScoreBuilder()
        let spanScores = builder.buildScores(
            spanEmbeddings: result.spanEmbeddings,
            structureEmbeddings: result.structureEmbeddings,
            spanMask: result.spanMask,
            predictedCount: result.predictedCount
        )
        if result.spanEmbeddings.count < 40 {
            let flattened = spanScores.values.flatMap { $0.flatMap { $0 } }
            let minScore = flattened.min() ?? 0
            let maxScore = flattened.max() ?? 0
            print("[DEBUG] GLiNER2 span score range: min=\(minScore) max=\(maxScore) labels=\(result.labels)")
        }
        guard !spanScores.values.isEmpty else { return [] }
        let t3 = clock.now

        let entities = spanDecoder.decode(
            scores: spanScores,
            labels: result.labels,
            threshold: config.threshold,
            text: text,
            wordRanges: encoding.textWordRanges
        )
        let t4 = clock.now

        let tokenizeMs = toMilliseconds(t0.duration(to: t1))
        let encodeMs = toMilliseconds(t1.duration(to: t2))
        let scoreMs = toMilliseconds(t2.duration(to: t3))
        let decodeMs = toMilliseconds(t3.duration(to: t4))
        let pretty: (Double) -> String = { value in
            String(format: "%.2f", value)
        }
        print("GLiNER2 ⏱️ Tokenize: \(pretty(tokenizeMs))ms | Encode: \(pretty(encodeMs))ms | Score: \(pretty(scoreMs))ms | Decode: \(pretty(decodeMs))ms")

        return entities
    }

    func extractEntitiesWithChunking(
        from text: String,
        labels: [String],
        config: Configuration
    ) async throws -> [Entity] {
        let chunks = textChunker.chunk(text: text)
        guard chunks.count > 1 else {
            return try await runExtraction(text: text, labels: labels, config: config)
        }
        var perChunk: [[Entity]] = []
        perChunk.reserveCapacity(chunks.count)
        for chunk in chunks {
            let chunkEntities = try await runExtraction(text: chunk.text, labels: labels, config: config)
            perChunk.append(adjust(entities: chunkEntities, offset: chunk.startOffset))
        }
        return chunkProcessor.mergeChunks(perChunk)
    }

    func adjust(entities: [Entity], offset: Int) -> [Entity] {
        guard offset != 0 else { return entities }
        return entities.map { entity in
            Entity(
                text: entity.text,
                label: entity.label,
                score: entity.score,
                start: entity.start + offset,
                end: entity.end + offset
            )
        }
    }
}

